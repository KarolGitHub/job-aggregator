# Job Aggregator (AIâ€‘Assisted)

A minimal, developerâ€‘friendly that **automatically collects frontend job offers from multiple sources, filters them using deterministic rules + AI classification, and delivers a daily curated summary** (email / Slack / Telegram).

This project is intentionally **not a full job board**. It is a personal productivity tool designed to eliminate manual browsing across multiple job portals.

---

## ðŸš€ Project Goals

- Eliminate daily manual searching across job portals
- Deliver **highâ€‘signal frontend job offers only**
- Keep the system **simple, transparent, and controllable**
- Use AI where it actually adds value (classification & cleanup)
- Be buildable in **1â€“2 evenings**

Nonâ€‘goals:

- Public job board
- User accounts
- Fullâ€‘text search UI
- Perfect data completeness

---

## âœ¨ Features (MVP Scope)

### Core

- ðŸ”„ Daily automated job fetching (cronâ€‘based)
- ðŸŒ Multiple data sources (RSS / JSON / light scraping)
- ðŸ§¹ Offer normalization (title, salary, location, description)
- ðŸ¤– AIâ€‘based classification:
  - frontend vs nonâ€‘frontend
  - seniority detection
  - tech stack extraction
  - spam / junk filtering
- ðŸ“¬ Daily summary delivery:
  - Email
  - Slack webhook
  - Telegram bot (optional)

### Filtering

- Frontend roles only
- Location (remote / city)
- Salary range (when available)
- Seniority level
- Technology keywords (Vue / React / etc.)

---

## ðŸ§  Why AI Is Used Here

AI **does not scrape websites**.

It is used strictly for:

- Semantic classification ("is this really frontend?")
- Normalizing inconsistent salary descriptions
- Extracting technologies from freeâ€‘text descriptions
- Rejecting lowâ€‘quality or agency spam offers

This keeps the system:

- Deterministic
- Auditable
- Cheap to run

---

## ðŸ§± Tech Stack

### Runtime

- **Node.js** (LTS)

### Data Fetching

- RSS parsing
- JSON endpoints (where available)
- Light HTML scraping (last resort)

### AI

- **OpenAI API** (classification only)

### Storage

- SQLite **or** local JSON files

### Scheduling

- `node-cron` **or** GitHub Actions (cron)

### Delivery

- SMTP (email)
- Slack Incoming Webhooks
- Telegram Bot API (optional)

---

## ðŸ—‚ï¸ Project Structure

```
job-aggregator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fetchers/        # Data source integrations
â”‚   â”‚   â”œâ”€â”€ nofluffjobs.js
â”‚   â”‚   â”œâ”€â”€ justjoinit.js
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ normalizer/      # Data normalization logic
â”‚   â”œâ”€â”€ ai/              # AI prompt & classification logic
â”‚   â”œâ”€â”€ filters/         # Deterministic filtering rules
â”‚   â”œâ”€â”€ storage/         # SQLite / JSON persistence
â”‚   â”œâ”€â”€ notifier/        # Email / Slack / Telegram
â”‚   â”œâ”€â”€ config.js        # User filters & thresholds
â”‚   â””â”€â”€ index.js         # Main entry point
â”œâ”€â”€ data/                # Local storage
â”œâ”€â”€ .env
â”œâ”€â”€ package.json
â””â”€â”€ README.md
```

---

## ðŸ§© Highâ€‘Level Architecture

```
[ Cron / Scheduler ]
          â†“
[ Fetch Job Offers ]
          â†“
[ Normalize Data ]
          â†“
[ AI Classification ]
          â†“
[ Deterministic Filters ]
          â†“
[ Deduplication ]
          â†“
[ Daily Summary Output ]
```

Each step is isolated and replaceable.

---

## ðŸ”„ How It Works (Step by Step)

1. **Scheduler triggers the job** (once per day)
2. Fetchers collect raw offers from selected sources
3. Raw offers are normalized into a unified format
4. AI classifies each offer and enriches metadata
5. Hard filters remove irrelevant or lowâ€‘quality offers
6. Previously seen offers are deduplicated
7. A daily summary is generated and sent

---

## ðŸ› ï¸ Getting Started

### Prerequisites

- Node.js >= 18
- OpenAI API key

### Installation

```bash
npm install
```

### Environment Variables

Create a `.env` file:

```
OPENAI_API_KEY=your_key_here
EMAIL_HOST=...
EMAIL_USER=...
EMAIL_PASS=...
SLACK_WEBHOOK_URL=...
```

### Configuration

Edit `src/config.js`:

- preferred locations
- minimum salary
- allowed tech stack
- delivery method

### Run Manually

```bash
node src/index.js
```

### Run Daily (Cron)

Using nodeâ€‘cron or GitHub Actions:

```bash
0 8 * * * node src/index.js
```

---

## ðŸ“¬ Example Output

```
ðŸ”¥ Frontend Jobs â€“ 2026â€‘01â€‘31

1. Frontend Vue Developer â€“ Remote â€“ 18â€“22k B2B
2. Frontend React Engineer â€“ KrakÃ³w â€“ 15â€“19k UoP
3. Senior Frontend â€“ Remote â€“ 22â€“26k B2B

(7 offers rejected as spam or nonâ€‘frontend)
```

---

## ðŸ—ºï¸ Roadmap

### Short Term

- Offer scoring (salary + stack + location)
- Better salary normalization
- Company blacklist / whitelist

### Mid Term

- History & trend tracking
- Click tracking (what you open)
- Multiple filter profiles

### Long Term (Optional)

- Minimal web dashboard
- Saved searches
- Public readâ€‘only mode

---

## âš ï¸ Legal & Ethical Notes

- Respect robots.txt and platform terms
- Prefer RSS and public APIs
- This project is intended for **personal use**

---

## ðŸ§  Philosophy

> This project optimizes for **signal over completeness**.
> Missing an offer is acceptable.
> Wasting time scrolling junk is not.

---
